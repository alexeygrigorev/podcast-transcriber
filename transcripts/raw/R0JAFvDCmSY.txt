0:02
Host
Welcome to Open Source Spotlight. We invite open source authors and ask them to show the tools they're working on. Today, we have Will. Hey, Will, tell us a few words about yourself and about the tool you want to show us. 

0:12
Guest
Yeah, so my name is Will. I'm a developer advocate at CESR. Uh, and, uh, yeah, my background comes from helping students get into open source. So being able to work on an open source project is, uh, really cool, and hopefully I can show you a little bit more about what EStra is all about today. Yeah, please do. Yeah, so let me jump into our demo. So jumping straight into Castra, um, One of the key, so Kestra is a unified orchestrator. Um, what Kestra allows you to do is take loads of different inputs, process those and get a load of different outputs, and you can do that on a schedule or you can do that event based. Um, now one of the key things that kind of different. Kestra from others is that you can, uh, do everything as code in YAML, or you can do it from the UI. So it kind of helped bridge this gap between some of technical and non-technical teams where, uh, you can have someone maybe set up your workflow, but then you can have someone not so technical. Also configure it, change a few things so they can get the desired output that they're after. So it sort of fits, you know, it's a one fit for all kind of product. Now, um, I'm gonna walk through a demo on how you can integrate your code into Castra and then basically integrate all of the cool bits of cash. into your code, so that, uh, your code, you know, is pretty much how you wrote it. It may be GitHub or whatever. But then Kestra can control that and, uh, really, you know, do whatever you want it to, depending on the inputs you give it. So, let's jump into that. So, here I'm gonna create a new workflow. And, uh, just to start with, I've got this one here just called Demo. Um, hopefully, that's visible. Um, now, as you can see here, I kind of get this sort of best of both worlds. So on the right, on the left here, I've got my YAO configuration. Now say what you will about YAO. Um, some people love it, some people hate it, you know, each, you know, you, you, you're, you, you know, you're allowed your own opinion. But, um, the thing that Kesha does is it appreciates that people don't like YAO, and the editor makes it a lot easier to edit. So, um, the autocomplete and the documentation, which I'll show you in a second, helps to sort of bridge that annoying gap that YAL provides. There's no issues with like indentations where you don't know where they are. The editor's pretty good at letting you know about that. So, um, here I've just got a very simple Helloworld example. I can see it on the left, on the right here as well, and I can edit all of these properties in the UI too. So if I don't want to add the, uh, properties in YAML or if I don't know what they are, such as maybe description, I can come in here and edit those as well. So again, it's quite a nice sort of in between. Now I mentioned about there being a documentation tab. Now this is one of my favorite parts of Questra, is that when you're editing your workflows, when you click on the task, you can see all of the documentation for that task right there. So here for the log task, I can easily see which properties it has, what outputs it will uh it will produce, and so on. So it makes it really easy to build quite quickly without having to constantly jump into the docks, figure out where you're supposed to look. Everything is just here in front of you. Now I know a few of you are probably wondering, but I don't want to use your editor. I want to be able to just use VS code or VIM. Am I allowed to do that? Of course you can, uh, you can, we've got a VS code plug-in that will help validate that your workflows in the correct format, but, um, you can also push stuff to Git and then pull it back from Git using some of our plugins. As well. So there's loads of options for whether you want to edit it in the UI, edit it in YAML in Kestra, build it on your own machine. There's options for all of these things. So something that suits everyone. And that's sort of the theme you'll see as we go through this demo, that Questra kind of fits, you know, everyone's needs to some degree. Now, the demo I'm going to show you today is, uh, going to use some Python. So let's get rid of this log task, and, uh, you'll see here immediately, I'm just gonna call this code, when I type in, uh, the type. You'll see that I get this huge auto completion already, uh, which can be a little overwhelming, but if I just search for Python, we'll get a bunch of different Python ones. Now I'm gonna use the uh Python script plug-in here, um, which is this one here, and we'll see that now I've got the documentation for that. It gives me some examples of how to run it. Now we have two different uh Python plug-ins and same for other languages. We've got a script one and a commands one. So the script is what I'm going to use today, which is where you can write your Python directly in your workflow. This is really useful if you've only got a few lines of Python to write or in my case you're trying to do a demo and you want it all to fit on the same screen. But um this is really handy if you want to be able to do that. But I appreciate people want to write their code, you know, locally, they're testing it locally, they're pushing it to Git. That's where the commands one comes in. You can pull your your files directly into Castra using a Git automation. You can then call commands to run them like you would on your own machine, so you don't have to try and awkwardly get them into your workflow. So, um, that's my personal preference when I'm writing workflows, but when I'm demoing, I typically use the script one because, uh, it's easier for people to see what's going on. Now looking at our documentation on the right here, all I need to do now is either add script to add um the actual Python, or I can put before commands to install any packages or anything that I might need. Now, um, I'm going to just put script for now and we'll add my bit of code that I have prepared off to the side here. Uh, and this is just a simple, very simple bit of code. All it's gonna do is it's gonna use Pandas to get a CSV file and it's gonna tell us the total. Nothing crazy, but we're going to continue to build off of this example. Now you're probably thinking you need pandas, right? So. If I need to install Pandas, that's where I can use the before commands to do a simple PI install Pandas. Now, um, it's worth noting that when you run these script tasks, they run themselves inside of a Docker container. So you don't need to worry about, you know, dealing with virtual environments and so on. Um, you can just, uh, install it here. But, um, I prefer to, instead of using, you know, before commands to install this every time, instead I can specify a container image that has that pre-installed. So I can, instead of having to write a huge list of things or maybe I have a requirements.txt in my git repository that I want to use, I can instead have all of that, those dependencies inside of an image, uh, which I will just quickly grab from here. We have this Python image, uh, that you can use in Castra, and you don't have to use it in Castra, it works with any container. Um, it's a very simple container image that's just called pi data, and that includes, I think, a few things like pandas, NumPy, and so on. So now if I press execute, what we'll see is we're going to get this wonderful Gantt chart that's going to say that it's creating our container, it's pulling that Docker image, and then it succeeds. And if I now go to logs, we can see it was all successful. But there's one key thing. That, uh, we can't really do is, uh, see our output. If I go to the outputs tab, we'll see that there isn't really any useful information here. So it's around our code, which is, you know, useful, but it'd be nice if we could see some of the outputs, understand what's gone on inside of our code beyond just what the, uh, the logs have said here. So that's where the Kestra library comes in. So now what I can do is using the Kestra Python library, I can easily, um, Uh, you can access this as an output. So here, I've just got this simple Kesha. output, and I just pass a dictionary with the data I want, and then I'll be able to see that in a second. So now when I put, uh, execute here, we're going to see that it's going to run it quite quickly because the image is pulled, hopefully. There we go. I'm. Now, if I go to outputs, well, see under VAs, I've got my total value here now, uh, and I can now use that in other tasks. So maybe I want to send that to Slack, maybe I want to, um, send it in an email, or maybe I want another task to process it or use that number. And this also works for output files, which will show off in a second. So, with that in mind, I'm now gonna show you how we can use that value in another task. So, that's our Python task. We're pretty happy with that at the moment. I can now, uh, create a log task like we had earlier, and I can just type log like so, and then we want to have a message. And now, simply using this outputs expression syntax, I can then put in VAS, and then we want to put in total, which is the name of the one that we've specified here. So now, if I press save and exit. Execute this, we'll see in our logs here, once it finishes executing our Python code, it does, in fact log that value. So, really useful because now I can use those values between tasks. And, uh, sort of to, you know, extend that a little bit further, we can, uh, also send it to Slack. I have this pre-made, uh, task here. Uh, that we'll just have a look at here. And here I can just send a slack message, and again, using that expression syntax here to, uh, inject it into my message. Now, you're probably wondering, what is this, this URL thing here? Now, um, Kesha does have secret management. Now, for the demo, I'm not going to use that because you configure it by adding the secrets to your Docker compose file as an environment. Variable. But here I'm using our key Value store to add my Slack webhook, which means that it's not visible inside of my workflow. So if I wanted to put this into version control, I haven't got to worry about accidentally putting sensitive information there, especially because when I have committed Slack webooks, you know, we've all done it. Uh, you get the annoying email from Slack to say that they've disabled your webook, then you have to make another one and change all of it. It's really annoying. So this is a nice way. to make sure that you don't do that. And, uh, I can easily go to our name spaces tab here and we'll go to the one that we had open. And if I go to, uh, Key Value store, you can see I can just easily add a bunch of different values that maybe I want to access between flows. I can also set these from my workflows. So this kind of adds a little bit of stapleness to your workflows. And we've got a couple of AWS ones that we'll, we'll use a little bit later, but, um, yeah, this is the, um, the, uh, key value store for being able to add a little bit of stapleness. So with that in mind, we'll go back to our demo here. 

10:32
Host
A quick question, so if I want to use uh this output total in another code in a in a in a different Python script in a different step, then I would use the same syntax, right? And they would just embedded in the script. 

10:47
Guest
In the same workflow or in a different workflow? Like 

10:50
Host
in the same flow, yeah. So let's say there is another task and the task is code 2, for example, and I want to use uh the output from the previous task there. 

11:00
Guest
Exactly. That is the one perk of using the script task is because the Python is in the workflow, you can put the expression straight into your code. So, uh, I'm actually, I can show you an example of that. Uh, we also have a concept called inputs. Now I'm just gonna call this data set. Um, now this is just gonna be a simple string, oh hang on, I didn't have the inputs, now. See, I told you that the Amore editor is aggressive when you forget to do stuff. Uh, and then here I can add a default value, and I can easily take our CSV link there, paste it up here, and now I can use that, uh, syntax here to add that in here. So now, um, when I run the code, it will take this value and put it in here. Now, the inputs are really handy because this allows you to change values at the point of execution. So, If you want to change different parameters that you want your Python script to use, for example, uh, when I press execute, or I'm in the developed version, so sometimes it doesn't always work. But if I click, uh, execute, you'll see that now I get an option to change this URL or I can have different options like numbers or, uh, yes, you know, true false or whatever. So there's lots of options there. And Um, if you wanted to do this in the commands one where you don't see your Python code, uh, my best technique is to, you can actually add these as an environment variable, and then you can just access that in your code as an environment variable. So that's the best way I found to be able to pass the values into your code, or you could save them as a file and then open that file in your code. Depends on what kind of data you're passing through. Um, so yeah, that's how you can got it, 

12:37
Host
got it. And um. Like, let's say we have 2 different steps, and each of these steps, Python steps, they require. Pandas, right? And we don't use the container image. Do I understand correctly that each step is run in a new container? So if I do people install Pandas in one, task, then I should also do Peep install Pandas in the other task. So it's not like preserved and it's run in a new completely separate container every time. 

13:08
Guest
Yes, so everything is isolated in their own containers, but you can set up plugin default, so you can say if I'm running a Python script task, I want to install, uh, I want it to do Pip install pandas for all of them. Um, but we've also had a few people where, and they're running Castra locally and they have it installed pit on the local machine. And then instead of using, um, the Docker image, a Docker container for running their code, they run it as a sub-process on the, on the Kestra instance. So that's one way they found to speed things up so they're not just installing pandas 

13:40
Host
all day. Yeah, because like if we have 10 steps and every time we need to install Numy pandas like. So I could learn, it will add up, right? 

13:49
Guest
Exactly. And you can configure some caching as well. So if you, you know, know that you're going to have pandas installed and you're using the subprocess, that also can help speed things up because I actually, when I started, started using subprocess over Docker because it was just quicker because I can have those things installed once and then I didn't have to worry about it for the rest of while I was fiddling with the workflow. 

14:09
Host
Yeah, yeah, thank you. No questions so far apart from this one. 

14:15
Guest
Cool. So we've got our input file here, um, that allows us to, uh, excuse me. Yeah, so here you can see I've just got that as an expression here quite nicely inside of the Python code. Um, what we can do now is actually generate, um, an output file. So to do that, what I'm gonna do is just extend our Python code a little bit further, so I'm actually gonna just, well just space it out a little bit. So here, I haven't copied that correctly, there we go. So here I'm now just gonna simply um create a new column in our table with a bunch of discounts and everything's going to be discounted 10%. And then it's going to save that to a CSV file. Now in order to actually save that as a CSV file, I need to specify an output file. Now if you don't know what your output file's gonna be, you can just simply put asterisks.csv. Uh, something is very unhappy with me. What have I done incorrectly here? Um, Unclear why it doesn't like that I've done, but. 51 2nd, try that again. It's happy now, so. Output files and then under output files we can put um I'm just gonna call it processed data. CSV. There we go. Uh, but you can put asterisks, maybe I'm getting the syntax wrong there, but you, if you don't know the actual name of the file, or you're gonna have lots of CSVs, you can do that. Um, so now if I was to execute this file uh flow, what we'll see here is that it will execute that, it will generate the file, and we'll be able to see that file here under outputs. So, um, here, if I go to code, output files, and then, uh. Yeah. We'll just try that again. Hm, no output files, interesting. Uh, it's because the uh CSV file that I, uh, I got my name wrong. Let's try that again. So here if I execute that, and actually while that's executing, you can see in Slack that that message that we specified earlier has been sending in the background. So, uh, quite convenient. Here we go. Output files, we can see we've got process CSV and then the nice thing about the outputs tab is you can preview these. So I can actually open the CSV file up. I can see it's got our discounted total. I can see that all the values are in fact 10% discounted. Uh, and I can also download that as well. So a good example would be maybe you have someone who is not super technical, they want to be able to get their CSV file once it's been processed, and then put it into a spreadsheet and do whatever they're gonna do with it. Um, they can come in here, they can execute it, they can maybe add any parameters they want and then get the data without necessarily having to touch the, uh, YAML configuration. So, um, now we've got our output file. Um, let's do something a little bit more with that. So, um. I like the fact that we have a discount here, but we can sort of do another example that shows off the fact that we can, uh, edit that using an expression. So here I'm going to, uh, define my input as a float. Uh, and I'm going to actually say that default, it's 0, so there's no discount by default, but I want to make sure that the user can't accidentally give it a number that's gonna break my logic here. And then what I can easily do is if I go down to here, I can now do a simple expression like so that does inputs.discountmos. So now it's going to do 1 minus the discount amount, so 0.1 to get the 0.9 that we had previously, and now we're able to generate that file, but I want to also make sure that if we haven't got a discount specified that it also isn't going to um you know, create this file unnecessarily. So here I can easily specify again another expression. To, uh, to see if the discount amount is, uh, greater than 00, hang on, we'll do it, not, well, we could do it in the expression because it will come back saying true or false, but I'll do it in the Python code to say, if it's greater than 0, then, you know, generate our CSV file. So, again, you can see where these expressions can come in quite handy to allow the Python code to be quite dynamic. So now if I was to execute this, I get this nice little value here. If I put in 0.1 like we had before, I will see that it will generate that file, um, like so. 

19:02
Host
I'm wondering if the next step always expects the output file. What will happen if this one does not produce it. 

19:10
Guest
So, that is a great question. So, uh, if the output file isn't generated, then you will get into an error, but that is where, um, I've got this quick, I'll just quickly add this example. So I want to, I'm just going to get rid of the Slack message so it stops pinging me in the background. I've got this S3 example here, uh, that's going to upload our CSV file to S3, but, um. What can I do to make sure that this doesn't run if the file doesn't exist? Now, like any programming language, we also have a conditional statement, so I can, uh, create a simple if statement called, uh, and I, I always forget what the full name of it is. So I'll type if and then scroll through it just trying to find it. There it is. Um, so here, I can simply put condition. And again, similar to that Python code, I can put inputs.co amount is greater than 0, and this condition will come back as true, and then I can put a den statement and indent all of that like so. And then now I can make sure that this doesn't accidentally try and upload a file that doesn't exist to S3. So, uh, and then you can see here I've specified that output file, let me just make that a little bit wider. I've specified that output file here. To uh look for the processed orders.csv as you can see we're just using a key here to access that file. And so this does mean it works if you have file names that have like a dash in them where typically YAML doesn't really like you to do that, um. So now if I was to execute this and I was to add. Uh, well, actually we'll do a, you know, we'll do something a bit different, 40% discount. Here I can see that, you know, it's going to process the file. Um, and I can see that it did, in fact, upload it to S3 because, in fact, it did exist, and I can actually go over here to the S3 bucket and see that it did, in fact, upload it, which is always useful. Um, but let's now get rid of that logic. Um, so we'll get rid of that logic here, and we'll just bring that back, and again, we'll get rid of this logic. Um, so, Yeah, we can see what an error message would look like. So 30% discount, it's gonna generate our file, it's gonna be happy days, um, and so on. Oh hang on. I, I put a discount in, didn't I? I need to put no discount. 

21:53
Host
Oh, you, right? 

21:54
Guest
I just need to get rid of the file altogether. That will work. There we go. So now. Give it time. There we go. So we see it failed here. It told us no idea where the file is, unable to approach this expression does not exist. Um, so, yeah, you know, a little bit frustrating that you can run into those scenarios. But, uh, there's actually a really cool feature with Kesha called Replay that allows you to sort of debug this a little bit. So if I click on the execution ID that failed. And go to like uh the logs here. I can see that this failed, but I can now replay this with a previous um revision of the code. So if I go back a few revisions and press OK. Um, what it will do is it won't work in this scenario because code didn't generate the file. But, um, what you can do with replay is if you make a typo in your Python code, but you don't want to have to rerun all of the steps that may fetched your data, then you can easily replay it with the made change to your code without having to rerun the whole workflow. So, just a few things there that helps speed things up a little bit for you. Um, So yeah, uh, now we, one last thing I'll mention is there's two other concepts we'll go through before we wrap this demo up is if we do run into an error, it would be quite handy to actually know that we ran into an error, um, so we can go and find out why, maybe because someone didn't write the right bit in the Python code. So here I can add this errors block. So we've got an inputs block for the inputs tasks for the things we want to run, and then an errors block. And the errors block is basically like the tasks block, but it only runs if you get a failed state. So, 

23:39
Host
right. Pardon? Like a trackage thing. Yeah, 

23:43
Guest
exactly. So now that we know this is definitely going to fail because there's no file for it to upload, um, I can press execute here and what we'll see is it's gonna try and run it. If it doesn't fail, then there'll be a, you know, there we go, it fails, but then it does in fact run our Slack notification. In fact, if I come over here we can see I've received this nice little slack notification to say. This is this, this is errored. If I want to view it, I can press this link. Annoyingly, that's opened it on my other tab, but it just opens this view where you can see the error message at the top here. And now I can easily go in and deal with that. Um, so it's quite useful if you want to either do alerting or maybe you need to change some, you know, run some other tasks to maybe stop other processes that may be running, um, quite, quite handy. And then the last thing we can do to this workflow to really automate it now is we've got this workflow that works. Let me just add that logic back into actually write the Python file cos that was quite useful. So now we've got a fully working fully functioning workflow. Um, now, I've got my errors all set up, but it would be nice if I didn't have to press, uh, execute every single time. So that's where Triggers comes in. Now, triggers can come in sort of two forms. You've got event-based ones that will happen when an event happens, such as like a file of Verizon S3, or maybe you receive a message in AWS SQS or vice versa, a web hook, for example. Um, I'm just gonna use a very simple schedule trigger, uh, very popular, a lot of people just want to run nightly jobs. Maybe you want this to generate your processed data CSV every day. Uh, I can easily just run a scheduled trigger, and then, uh, it just uses a chronic expression, really simply. So, um, we do. have a few extra expressions like at daily that will run it at midnight UTC, but, uh, I can just put in a simple one like this that will run it at 10 a.m. every day. So now this workflow has, uh, lots of parameters. I can specify some of these inputs in that trigger if I want to. Uh, or I can leave them to their default value. I could have different triggers with different inputs, so maybe I want it to run with one discount at 10 a.m. and then a different discount at 40 a.m. or different dates. Uh, then it will run my code, and if it runs into an error, it will let me know about that. And if I actually go back to that topology view, it's got a little bit busier since we last looked at it. I can see it's got the trigger, we've got our code of the log and the S3 upload. We've got that slack notification in case something does go wrong. Um, and if I go to that triggers tab, or if I give it a save. I don't know why, hang on a second. I go to that triggers tab, we can see in here that the trigger is set up. We can see it's gonna run it tomorrow at 10:00 a.m., which is in just about 24 hours' time, um, which is useful. And, uh, this, this is in your, uh, your, the time that you have your, uh, instance set to, uh, sorry, your UI set to, not the instance. The instance will always execute things at UTC, um, but you can just change that if you would like to. So, um, yeah, sort of a quick sort of overview of Kestra and how you can take a very simple Python script to make it very dynamic and easily connected into other things. Um, yeah, any, any questions? Yeah, 

26:54
Host
like, uh, let's say you want to based on the date that like we have a trigger right and trigger works like, I don't know, we want to, we know that today is uh 7th of November. So what we want to do is to run our pipeline for 6th of November, right? How do we do it here? 

27:15
Guest
Yeah. So on top of Cron, we also have this property called conditions. Now, I would be lying if I could remember all of the conditions properties. Uh, it might actually give me a few in the example here. So here you can see, I can specify it to work on specific days. Of the week in a month or uh there's lots of no 

27:34
Host
no like this is not what I meant. It's more like how do I use this in my Python code. So I want to know what was the day yesterday, so especially if I do back fields like let's say I saw that there is a backfield thing, so I imagine that I can retroactively run it for yesterday, one week before. So for each of these rounds, I want to know what was the day yesterday. 

27:57
Guest
Yeah, so similar to the inputs and the outputs, we can also do an expression in our Python code with the trigger. So you can easily do trigger dot and then you can get the date. So you can easily find out in your code when it was triggered, um, and if you're using like an event-based, uh, trigger such as like a web hook, that also has a bunch of information there that you can then use in your workflow. 

28:20
Host
I understand. Cool. And like remember you showed us an example with the if statement. I'm wondering how it would look like uh when you put it back, like how the diagram will look like. 

28:32
Guest
Yeah. Good question. Let me add that back in. Uh, the diagram will look like I can actually go to the full, the full view, here you go. So here it just highlights that these are blocked into each other like so. 

28:47
Host
And uh like we have a bunch of tasks, do they always, are they always run sequentially, one after another, or there is like a smart way of figuring out, OK, there is some dependency, we need to run this thing first, but then these two we can run in parallel. Or stuff like that. 

29:03
Guest
Yeah, so, um, we've got a load of, we call them flowable tasks. They're all the ones that are sort of the orchestration logic. So we've got a bunch of them that let you run things in parallel or you can loop over something. So it's a few 4 each. So if you have a Python script that you want to hand it different values each time it runs, you can do that as well. So, uh, there's lots of options to sort of, in fact, I can quickly go to our blueprint examples. We've got uh. For example, here you can see it's gonna run this Air by one in parallel, um, before handing it over to DBT and you can see in this example, it just specifies these three tasks, but it will just do all three of them at the same time. And you'll see that in the chart as well, where it will break it out nicely to easily show you how that works. 

29:46
Host
This is not what exactly I asked, but like this answer is actually better. OK, and what I had in mind was like my original question was, let's say I have, like, do I always have to keep in mind that uh. Like, do tasks always run sequentially? For example, if I have an output in one task, right? It always has to, like the task that I depend on always have to be before. 

30:11
Guest
Yes, class will always run sequentially, which means unless you start messing around with some of those extra things like parallel or 4 each. So you can always rely that this log message will not run until it is, until this Python code is run, and it means you can guarantee that that output will exist by the time it gets. 

30:28
Host
And if I put it in front, like if first execute log and then the code task, then it will fail, 

30:34
Guest
right? Exactly. So, we can just easily show that that will fail immediately because it won't know what it is. But if you, for some reason, you're happy for that to fail, because in this scenario, it is just a log message. We can add and allow failure property to true, so it will just leave it as a warning message. So if you've got like a notification, but let's say slacks down and you don't want that to cause the whole of your workflow to crash, uh, you can see, it still ran. It was still happy to run, but it still, it will still finish with a warning state to let you know that something not quite right happened. 

31:06
Host
Yeah, and at the beginning, you said that uh you help students to get into open source, right? So if somebody wants to get into open source and contribute to Castra, how do they go about that? 

31:18
Guest
Yeah, so we are big fans of people who want us to make contributions. Uh, Castro is a rapidly growing product, and so there are often, you know, little things that you might spot that aren't quite right or maybe little typos. So if you want to, uh, contribute and get give back, then you can find us on GitHub. Uh, we've got a bunch of issues that have that, um, good first issue tag, so you can see there's one here. Uh, in fact, we've had about 10 new contributors in the last month, part of October 1st, who just got involved with either they found issues and they sort of got lots of information for them, or they jumped on and helped to fix those. So, uh, if you are looking to get involved, then the good first issue is definitely a great place to start. Um, but it is worth noting that the Castro repo itself is just the product. Every single plug-in has its own set. For Repo too. So if you want to fix something for like the AWS one, then you need to go to the AWS one. But there again, there's good first issue tags on all of those. So, uh, definitely, if you've got a preference or I want to go contribute to the AWS plug-in, then have a look there first. 

32:20
Host
Would it be a good idea to first, uh, join Slack and ask there, like, hey, I'm thinking of working on this particular issue. 

32:28
Guest
Yeah, so, uh, we've also got a Slack. I'd recommend joining that too. You can see it here in the, uh, GitHub Read Me. Um, the Slack is a really, we've got a contributors channel too, so it's a good place to ask, especially for some of the bigger issues. Um, but yeah, if you find an issue that you like the look of, feel free to comment on that. Ask us if that's something. Uh, we're trying to get better at making it clear on issues that we're handling in terms. So that you don't end up trying to do duplicate work. So it makes it really easy for someone who's just found the project and wants to get started to get involved and make a meaningful impact. But if you're unsure, the Slack community is definitely the best place to go. Uh, we've got people there who are also willing to help you get set up with a development environment too. So if you're struggling to get Kestra running and testing it, then, uh, definitely come into the Slack and ask some questions there. Yeah, 

33:15
Host
thank you. I know we run a bit of, um, We are taking a bit longer time, but I cannot not ask this question, so this is the last question I'll ask you is if you have any advice to anyone who is watching this. 

33:28
Guest
Any advice. So, um, my advice is that, um, even if like you're wanting to get into open source, you're not sure, uh, there's always easy ways to get started, whether that is helping people like me contributing to the docs, uh, or helping, you know, people write actual code. There's always something you can do to. To get started. And it is overwhelming as it might be to start contributing to open source, um, it only gets easier once you get started. So, you know, start small, gradually work your way up, and you'll start feeling really confident. And the best bit is, you'll do some really cool stuff as part of that, so. Yeah, the sort of takeaway is, uh, don't be afraid to contribute to open source. There are plenty of projects out there that are willing to take on contributors and have plenty of easy issues to get started, um, but yeah, don't be put off by the big codebass. 

34:19
Host
Amazing. Thank you, Will, and please everyone don't forget to give Castro a star. It's an amazing project. Um, you'll find the link in the description. So go there to GitHub, give them a star, and again, thanks Will for doing the demo. Thank 

34:33
Guest
you so much.